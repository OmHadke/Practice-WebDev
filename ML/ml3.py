# -*- coding: utf-8 -*-
"""231210046_Lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fvc9tZTZTP-St-tCcfc-hkLd5RhXlicf
"""

import numpy as np
import pandas as pd
import os
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline

# Load dataset from CSV (adjust filename as needed)
csv_path = 'ENB2012_data.csv'
energy_data = None
if os.path.exists(csv_path):
    print(f"Loading dataset from local file: {csv_path}")
    energy_data = pd.read_csv(csv_path)
else:
    # Try to download a canonical source (xlsx on UCI is common). If that fails, create synthetic data.
    try:
        print("Local dataset not found â€” attempting to download a canonical copy...")
        url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'
        # pandas can read excel directly from URL if openpyxl is available; attempt it and fall back to synthetic
        energy_data = pd.read_excel(url, engine='openpyxl')
        print("Downloaded dataset from UCI (ENB2012)")
    except Exception:
        print('Could not download dataset; creating a synthetic dataset for demo (768 samples, 8 features).')
        np.random.seed(42)
        # create synthetic data similar in shape to ENB2012: 8 features and two targets
        n = 768
        X_synth = np.random.rand(n, 8) * np.array([10, 1, 1, 10, 1, 1, 1, 1])
        y1 = 20 + 5 * np.random.rand(n)  # heating load-ish
        y2 = 10 + 5 * np.random.rand(n)  # cooling load-ish
        cols = [f'X{i+1}' for i in range(8)]
        energy_data = pd.DataFrame(X_synth, columns=cols)
        energy_data['Y1'] = y1
        energy_data['Y2'] = y2

# Select features (first 8 columns)
X = energy_data.iloc[:, :-2].values

# Targets
y1 = energy_data.iloc[:, -2].values  # Heating Load (Y1)
y2 = energy_data.iloc[:, -1].values  # Cooling Load (Y2)

def bias_variance_tradeoff(X, y, target_name):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    train_rmse = []
    test_rmse = []
    degrees = range(1, 11)

    for degree in degrees:
        model = Pipeline([
            ('poly', PolynomialFeatures(degree=degree)),
            ('scaler', StandardScaler()),
            ('linreg', LinearRegression())
        ])
        model.fit(X_train, y_train)
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        train_rmse.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))
        test_rmse.append(np.sqrt(mean_squared_error(y_test, y_test_pred)))

    print(f"Generating bias-variance plot for {target_name}...")
    plt.figure(figsize=(10,6))
    plt.plot(degrees, train_rmse, marker='o', label='Training RMSE')
    plt.plot(degrees, test_rmse, marker='o', label='Testing RMSE')
    plt.xlabel('Polynomial Degree')
    plt.ylabel('RMSE')
    plt.title(f'Bias-Variance Tradeoff for {target_name}')
    plt.xticks(degrees)
    plt.legend()
    plt.grid(True)
    # Save figure to file (sanitize target_name for filename)
    safe_name = ''.join(c if c.isalnum() else '_' for c in target_name)
    out_file = f'bias_variance_{safe_name}.png'
    fig = plt.gcf()
    fig.savefig(out_file, dpi=300, bbox_inches='tight')
    plt.close(fig)
    print(f"Saved: {out_file}")

# Plot for Heating Load (Y1)
bias_variance_tradeoff(X, y1, 'Heating Load (Y1)')

# # Plot for Cooling Load (Y2)
# bias_variance_tradeoff(X, y2, 'Cooling Load (Y2)')

bias_variance_tradeoff(X, y2, 'Cooling Load (Y2)')
