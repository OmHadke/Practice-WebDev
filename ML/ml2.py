# -*- coding: utf-8 -*-
"""231210046_LAB2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DIgeWkWoRgRxFJrXR8lEPQvKDMd-DAwQ
"""

import numpy as np
import pandas as pd
import seaborn as sns
import os
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

"""## **Linear Regression**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score

boston_df = None
try:
    boston_df = pd.read_csv('housing.csv')
    print('Loaded local housing.csv')
except Exception:
    print('housing.csv not found — creating synthetic Boston-style dataset for demo')
    np.random.seed(42)
    # minimal set of columns used later plus RM and MEDV
    n = 200
    boston_df = pd.DataFrame({
        'CRIM': np.random.rand(n) * 10,
        'ZN': np.random.choice([0, 12.5, 25, 75], n),
        'INDUS': np.random.rand(n) * 30,
        'CHAS': np.random.choice([0, 1], n),
        'AGE': np.random.rand(n) * 100,
        'LSTAT': np.random.rand(n) * 40,
        'RM': np.random.rand(n) * 5 + 3,
        'MEDV': np.random.rand(n) * 30 + 5
    })
boston_df.head()

boston_df.shape

boston_df.info()

boston_df.isnull().sum()

boston_df = boston_df.dropna(subset=['CRIM','ZN','INDUS','CHAS','AGE','LSTAT'])
boston_df.isnull().sum()

boston_df.shape

X = boston_df[['RM']]
Y = boston_df['MEDV']

boston_df['RM'].std()

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
X_train.shape,X_test.shape,X.shape

linear_model = LinearRegression()
linear_model.fit(X_train,Y_train)

from sklearn.metrics import mean_squared_error, r2_score

# Predict on training data
X_train_predicted = linear_model.predict(X_train)

# Calculate MSE and R² on training data
mse_train = mean_squared_error(Y_train, X_train_predicted)
r2_train = r2_score(Y_train, X_train_predicted)

print("Training MSE:", mse_train)
print("Training R²:", r2_train)

# Predict on test data
X_test_predicted = linear_model.predict(X_test)

# Calculate MSE and R² on test data
mse_test = mean_squared_error(Y_test, X_test_predicted)
r2_test = r2_score(Y_test, X_test_predicted)

print("Test MSE:", mse_test)
print("Test R²:", r2_test)

import matplotlib.pyplot as plt

# Predict on test data
y_pred = linear_model.predict(X_test)

plt.figure(figsize=(8, 6))

# Scatter plot: Actual vs Predicted
plt.scatter(Y_test, y_pred, color='blue', alpha=0.6)

# Plot a diagonal line for perfect prediction
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', lw=2)

plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.grid(True)
out_file = 'ml2_linear_actual_vs_predicted.png'
plt.tight_layout()
plt.savefig(out_file, dpi=300, bbox_inches='tight')
plt.close()
print(f"Saved: {out_file}")

"""## **Multiple Regression**"""

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix

student_df = None
try:
    student_df = pd.read_csv('student.csv')
    print('Loaded local student.csv')
except Exception:
    print('student.csv not found — creating synthetic student dataset for demo')
    np.random.seed(0)
    n = 300
    student_df = pd.DataFrame({
        'hours_studied': np.random.uniform(0, 20, n),
        'attendance': np.random.uniform(50, 100, n),
        'assignments': np.random.randint(0, 10, n),
        'participation': np.random.uniform(0, 10, n),
        'GPA': np.clip(np.random.normal(3.0, 0.5, n), 0.0, 4.0)
    })
student_df.head()

student_df.shape

student_df.info()

student_df.isnull().sum()

arr = student_df.values.flatten()
overall_std = np.std(arr)
overall_std

X = student_df.drop('GPA',axis=1)
Y = student_df['GPA']

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
X.shape,X_train.shape,X_test.shape

scaler = StandardScaler()
X_train_standardized = scaler.fit_transform(X_train)
X_test_standardized = scaler.fit_transform(X_test)

np.std(X_train_standardized)

np.std(X_test_standardized)

mul_lin = LinearRegression()
mul_lin.fit(X_train_standardized,Y_train)

from sklearn.metrics import mean_squared_error, r2_score

# Predict on training data
X_train_predicted = mul_lin.predict(X_train_standardized)

# Calculate MSE and R² on training data
mse_train = mean_squared_error(Y_train, X_train_predicted)
r2_train = r2_score(Y_train, X_train_predicted)

print("Training MSE:", mse_train)
print("Training R²:", r2_train)

# Predict on test data
X_test_predicted = mul_lin.predict(X_test_standardized)

# Calculate MSE and R² on test data
mse_test = mean_squared_error(Y_test, X_test_predicted)
r2_test = r2_score(Y_test, X_test_predicted)

print("Test MSE:", mse_test)
print("Test R²:", r2_test)

import matplotlib.pyplot as plt

# Predict on test data
y_pred = mul_lin.predict(X_test_standardized)

plt.figure(figsize=(8, 6))

# Scatter plot: Actual vs Predicted
plt.scatter(Y_test, y_pred, color='blue', alpha=0.6)

# Plot a diagonal line for perfect prediction
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', lw=2)

plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.grid(True)
out_file = 'ml2_multiple_actual_vs_predicted.png'
plt.tight_layout()
plt.savefig(out_file, dpi=300, bbox_inches='tight')
plt.close()
print(f"Saved: {out_file}")

"""## **Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

breast_df = None
try:
    breast_df = pd.read_csv('breast.csv')
    print('Loaded local breast.csv')
except Exception:
    print('breast.csv not found — creating synthetic breast cancer dataset for demo')
    np.random.seed(1)
    n = 200
    # create numeric features and diagnosis label
    breast_df = pd.DataFrame(np.random.randn(n, 10), columns=[f'feat{i}' for i in range(10)])
    breast_df['diagnosis'] = np.random.choice(['B', 'M'], n, p=[0.6, 0.4])
breast_df.head()

breast_df.shape

breast_df.info()

breast_df.isnull().sum()

X = breast_df.drop('diagnosis', axis=1)
Y = breast_df['diagnosis']

numeric_df = breast_df.select_dtypes(include=[np.number])

# Flatten the numeric values
arr = numeric_df.values.flatten()

# Now calculate standard deviation
overall_std = np.std(arr)
print(overall_std)

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
X.shape,X_train.shape,X_test.shape

scaler = StandardScaler()
X_train_standardized = scaler.fit_transform(X_train)
X_test_standardized = scaler.fit_transform(X_test)

np.std(X_train_standardized)

np.std(X_test_standardized)

log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train_standardized,Y_train)

train_predictions = log_model.predict(X_train_standardized)
train_accuracy = accuracy_score(train_predictions, Y_train)

test_predictions = log_model.predict(X_test_standardized)
test_accuracy = accuracy_score(test_predictions, Y_test)

print("\nModel Accuracy:")
print(f"Training Accuracy: {train_accuracy}")
print(f"Testing Accuracy: {test_accuracy}")

test_f1 = f1_score(Y_test, test_predictions, pos_label='M')
test_recall = recall_score(Y_test, test_predictions, pos_label='M')
test_precision = precision_score(Y_test, test_predictions, pos_label='M')

print(f"F1 Score: {test_f1:.3f}")
print(f"Recall: {test_recall:.3f}")
print(f"Precision: {test_precision:.3f}")

from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Confusion matrix plot for test data
cm = confusion_matrix(Y_test, test_predictions, labels=['B', 'M'])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])

plt.figure(figsize=(6,6))
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix - Test Data")
out_file = 'ml2_confusion_matrix.png'
plt.tight_layout()
plt.savefig(out_file, dpi=300, bbox_inches='tight')
plt.close()
print(f"Saved: {out_file}")
