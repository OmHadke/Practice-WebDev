# -*- coding: utf-8 -*-
"""Assign_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13QMOJfEpW3hwUWxf-fqFXeTeRA3V5UG1
"""



# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the Pima Diabetes dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=column_names)

# Explore the dataset
print("Dataset Shape:", df.shape)
print("\nFirst few rows:")
print(df.head())
print("\nDataset Info:")
print(df.info())
print("\nStatistical Summary:")
print(df.describe())
print("\nMissing Values:")
print(df.isnull().sum())

# Check for zero values in features where zero is not meaningful
print("\nZero values in each column:")
print((df == 0).sum())

# Split features and target
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Replace zero values with median for relevant features
# Features where 0 is not a valid biological value
features_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

for feature in features_with_zeros:
    # Replace 0 with NaN
    X[feature] = X[feature].replace(0, np.nan)
    # Fill NaN with median
    median_value = X[feature].median()
    X[feature] = X[feature].fillna(median_value)

print("\nAfter replacing zeros with median:")
print(X.describe())

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining set size: {X_train.shape[0]}")
print(f"Testing set size: {X_test.shape[0]}")

# Dictionary to store results
results = {}

# 1. Baseline Decision Tree Classifier
print("\n" + "="*60)
print("1. BASELINE DECISION TREE CLASSIFIER")
print("="*60)
dt_baseline = DecisionTreeClassifier(random_state=42)
dt_baseline.fit(X_train, y_train)
y_pred_baseline = dt_baseline.predict(X_test)
accuracy_baseline = accuracy_score(y_test, y_pred_baseline)
results['Baseline Decision Tree'] = accuracy_baseline

print(f"Accuracy: {accuracy_baseline:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_baseline))

# 2. Bagging Classifier
print("\n" + "="*60)
print("2. BAGGING CLASSIFIER")
print("="*60)
bagging_model = BaggingClassifier(
    estimator=DecisionTreeClassifier(random_state=42),
    n_estimators=100,
    random_state=42,
    n_jobs=-1
)
bagging_model.fit(X_train, y_train)
y_pred_bagging = bagging_model.predict(X_test)
accuracy_bagging = accuracy_score(y_test, y_pred_bagging)
results['Bagging'] = accuracy_bagging

print(f"Accuracy: {accuracy_bagging:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_bagging))

# 3. AdaBoost Classifier (Boosting)
print("\n" + "="*60)
print("3. ADABOOST CLASSIFIER (BOOSTING)")
print("="*60)
boosting_model = AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),
    n_estimators=100,
    random_state=42,
    algorithm='SAMME'
)
boosting_model.fit(X_train, y_train)
y_pred_boosting = boosting_model.predict(X_test)
accuracy_boosting = accuracy_score(y_test, y_pred_boosting)
results['Boosting (AdaBoost)'] = accuracy_boosting

print(f"Accuracy: {accuracy_boosting:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_boosting))

# 4. Stacking Classifier
print("\n" + "="*60)
print("4. STACKING CLASSIFIER")
print("="*60)

# Define base learners with varying parameters
base_learners = [
    ('dt1', DecisionTreeClassifier(max_depth=3, random_state=42)),
    ('dt2', DecisionTreeClassifier(max_depth=5, random_state=42)),
    ('dt3', DecisionTreeClassifier(max_depth=7, random_state=42)),
    ('knn', KNeighborsClassifier(n_neighbors=5)),
    ('lr', LogisticRegression(max_iter=1000, random_state=42))
]

# Meta-estimator (Decision Tree)
meta_estimator = DecisionTreeClassifier(random_state=42)

# Create and train stacking classifier
stacking_model = StackingClassifier(
    estimators=base_learners,
    final_estimator=meta_estimator,
    cv=5,
    n_jobs=-1
)
stacking_model.fit(X_train, y_train)
y_pred_stacking = stacking_model.predict(X_test)
accuracy_stacking = accuracy_score(y_test, y_pred_stacking)
results['Stacking'] = accuracy_stacking

print(f"Accuracy: {accuracy_stacking:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_stacking))

# Compare all results
print("\n" + "="*60)
print("COMPARISON OF ALL METHODS")
print("="*60)
results_df = pd.DataFrame(list(results.items()), columns=['Method', 'Accuracy'])
results_df = results_df.sort_values('Accuracy', ascending=False)
print(results_df.to_string(index=False))

# Visualization 1: Accuracy Comparison Bar Plot
plt.figure(figsize=(10, 6))
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
bars = plt.bar(results.keys(), results.values(), color=colors, edgecolor='black', linewidth=1.5)
plt.xlabel('Ensemble Method', fontsize=12, fontweight='bold')
plt.ylabel('Accuracy', fontsize=12, fontweight='bold')
plt.title('Comparison of Ensemble Methods on Pima Diabetes Dataset',
          fontsize=14, fontweight='bold')
plt.ylim([0.6, 0.9])
plt.xticks(rotation=15, ha='right')
plt.grid(axis='y', alpha=0.3, linestyle='--')

# Add value labels on bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.4f}',
             ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('ensemble_comparison.png', dpi=300, bbox_inches='tight')
plt.close()

# Visualization 2: Confusion Matrices
fig, axes = plt.subplots(2, 2, figsize=(14, 12))
predictions = [y_pred_baseline, y_pred_bagging, y_pred_boosting, y_pred_stacking]
titles = ['Baseline Decision Tree', 'Bagging', 'Boosting (AdaBoost)', 'Stacking']

for idx, (ax, y_pred, title) in enumerate(zip(axes.flat, predictions, titles)):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                cbar_kws={'label': 'Count'})
    ax.set_xlabel('Predicted Label', fontweight='bold')
    ax.set_ylabel('True Label', fontweight='bold')
    ax.set_title(f'{title}\nAccuracy: {results[list(results.keys())[idx]]:.4f}',
                 fontweight='bold')

plt.tight_layout()
plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')
plt.close(fig)

# Calculate improvement over baseline
print("\n" + "="*60)
print("IMPROVEMENT OVER BASELINE")
print("="*60)
baseline_acc = results['Baseline Decision Tree']
for method, acc in results.items():
    if method != 'Baseline Decision Tree':
        improvement = ((acc - baseline_acc) / baseline_acc) * 100
        print(f"{method}: {improvement:+.2f}%")

print("\n" + "="*60)
print("KEY INSIGHTS")
print("="*60)
best_method = max(results, key=results.get)
print(f"✓ Best performing method: {best_method} with accuracy: {results[best_method]:.4f}")
print(f"✓ Baseline Decision Tree accuracy: {baseline_acc:.4f}")
print(f"✓ All ensemble methods evaluated successfully!")