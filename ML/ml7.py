# -*- coding: utf-8 -*-
"""lab_7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HVlBsDVH512vIx3l9TC5OKv2xLmvFBJT
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load Sentiment140 dataset
print("Loading Sentiment140 dataset...")
cols = ['target', 'ids', 'date', 'flag', 'user', 'text']

# Try to load real dataset, fallback to synthetic if unavailable
df = None
try:
    import requests
    import zipfile
    import io
    url = "https://archive.org/download/sentiment140/trainingandtestdata.zip"
    print("Downloading Sentiment140 dataset (this may take a moment)...")
    r = requests.get(url, timeout=30)
    z = zipfile.ZipFile(io.BytesIO(r.content))
    # Load only first 50k rows for faster testing
    with z.open('training.1600000.processed.noemoticon.csv') as f:
        df = pd.read_csv(f, encoding='latin-1', names=cols, nrows=50000)
    print(f"Dataset loaded: {len(df)} samples")
except Exception as e:
    print(f"Warning: Could not load from URL: {e}")
    print("Creating synthetic sentiment dataset for demo...")
    np.random.seed(42)
    sample_texts = [
        "this movie is great and i loved it", "terrible film waste of time", "it was okay nothing special",
        "amazing performance by the actors", "boring and predictable", "best movie ever made",
        "not worth watching at all", "pretty good overall", "absolutely fantastic", "really bad acting"
    ]
    df = pd.DataFrame({
        'target': np.random.choice([0, 2, 4], 5000),
        'ids': np.arange(5000),
        'date': ['2009-06-01'] * 5000,
        'flag': ['NO_QUERY'] * 5000,
        'user': [f'user_{i}' for i in range(5000)],
        'text': [np.random.choice(sample_texts) for _ in range(5000)]
    })
    print(f"Synthetic dataset created: {len(df)} samples")


# Display sample data
print("\nDataset preview:")
print(df.head())

print("\nProcessing data...")
# Map sentiment values: 0 → Negative, 2 → Neutral, 4 → Positive
df['target'] = df['target'].replace({0: 'negative', 2: 'neutral', 4: 'positive'})

# Retain only necessary columns
df = df[['text', 'target']]

# Drop duplicates and missing values
df.drop_duplicates(inplace=True)
df.dropna(inplace=True)

print(f"Final dataset size: {len(df)} samples")
print("\nClass distribution:")
print(df['target'].value_counts())

# Split data into training and testing sets (80:20)
print("\nSplitting data...")
X_train, X_test, y_train, y_test = train_test_split(
    df['text'], df['target'], test_size=0.2, random_state=42, stratify=df['target'])

# Convert text into numerical features
print("Vectorizing text...")
vectorizer = CountVectorizer(max_features=5000, stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

print(f"Vocabulary size: {len(vectorizer.get_feature_names_out())}")

# Initialize and train model
print("Training Naive Bayes classifier...")
nb_classifier = MultinomialNB()
nb_classifier.fit(X_train_vec, y_train)

# Predict on test data
print("Generating predictions...")
y_pred = nb_classifier.predict(X_test_vec)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy: {accuracy * 100:.2f}%")

# Classification Report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
print("\nGenerating confusion matrix visualization...")
cm = confusion_matrix(y_test, y_pred)
fig = plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Neutral', 'Positive'],
            yticklabels=['Negative', 'Neutral', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Naive Bayes Sentiment Analysis')
fig.savefig('ml7_confusion_matrix.png')
plt.close(fig)

print("\nAll visualizations saved! Check: ml7_confusion_matrix.png")